\section{Theorie}
\label{sec:Theorie}
Das IceCube Experiment ist ein Array aus Photodedektoren, die am geografischen Südpol im Eis eingefroren sind. Dabei befinden sich 5160 Photodedektoren
in einer Tiefe zwischen $\SI{1450}{\meter}$ und $\SI{2450}{\meter}$. Das Ziel ist kosmische Neutrinos zu detekieren, dazu wird das Cerenkovlicht der sekundär
Teilchen aus Neutrinowechselwirkungen gesucht. Da aber noch viele andere Teilchen IceCube durchqueren, müssen die Daten gefiltert werden. Ein erster Filter ist die
Richtung, aus der das Teilchen kam. Die gesuchten Neutrinos kommen aus dem Boden, so das die Erde als Abschirmung gegen die restliche Kosmische Strahlung
wirkt. Da die Richtungsauflösung aber nicht so genau ist, müssen weitere Filter angewand werden, um ein signifikantes Signal zu erhalten. Dazu werden mit Hilfe
von machine learning Algorithmen trainiert, die die weitere Auswertung durchführen.
\subsection{machine learning}
Machine learning wird oft zur Klassifizierung von Daten eingesetzt. Ein Algorithmus muss dazu mit bereits klassifizierten Daten trainiert werden. Häufig hat ein
Datensatz eine vielzahl an Attributen oder Features. Es können alle Features an der Lerner übergeben werden, dies erhöht aber die Rechenzeit. Effizienter ist
es, die Features voher auszuwählen, die übergeben werden.
%Hier feature_selection einfügen
\subsection{Jaccard-Index}
Der Jaccard-Index $J$ beschreibt die Ähnlichkeit zweier Mengen. Er wird nach Formel \eqref{eqn:jaccard} bestimmt.
\begin{equation}
	J=\frac{|F_a \cup F_b|}{|F_a \cap F_b|}
	\label{eqn:jaccard}
\end{equation}
Die Featureauswahl wird $l$-mal auf $l$ Teilmengen ausgeführt nach Formel \eqref{eqn:jaccard_tilde}. Ein Wert nahe eins deutet auf eine gute Auswahl.
\begin{equation}
	\tilde{J} =\frac{2}{l(l-1)}\sum_{i=1}^l \sum_{j=i+1}^l J(F_i,F_j)
	\label{eqn:jaccard_tilde}
\end{equation}

Es werden drei verschiedene Lerner verwendet, ein Naive-Bayes, ein  k-Nächste-Nachbarn und ein Random-Forest Diese werden in Folgenden genauer erklärt.
\subsection{Naive Bayes}
Das Bayes'sche Theorem besagt
\begin{equation}
	p(A|B)=\frac{p(B|A)p(A)}{p(B)}.
\end{equation}
Mit den Klassen Signal $A$ und Untergrund $\overline{A}$ und dem Feature $B$ nimmt der Wahrscheinlichkeitsquotient $Q$ \eqref{eqn:bayes} einen Wert größer als
eins an, wenn ein Ereignis wahrscheinlicher Signal als Untergrund ist.
\begin{equation}
	Q=\frac{p(A|B)}{p(\overline{A}|B)} = \frac{p(B|A)p(A)}{p(B|\overline{A})p(\overline{A})}
	\label{eqn:bayes}
\end{equation}
Für mehrere Features wird das Produkt der Einzelquotienten genommen.
\subsection{k Nächste Nachbarn}
Bei dem k Nächste Nachbarn werden die Features als Dimensionen interpretiert. Die einzelen Daten entsprechen dann Punkten in diesem Raum. Bei dem zu
Klassifizierenden Punkt werden dann die k nächsten Nachbarn gemittelt. Dafür kann jede Abstandsdefinition genutzt werden, in der Regel ist es aber der
Euklidische Abstand.
\subsection{Random Forest}
Der Random Forest ist ein Binärer Baum, bei dem an jedem Knoten eine Zufällige Entscheidung getroffen wird. Jedem Blatt ist eine Klassifizierung zugeordnet.
In der Regel wird nicht nur ein Baum aufgestellt, sondern über eine Vielzahl gemittelt. Dadurch wird ein Übertrainieren, das heißt eine Spezialisierung auf die
Trainingsdaten aber schlechte Ereignisse bei Unbekannten, verhindert.
\subsection{Bewertung}
Eine Binäre Klassifizierung kann vier Ergebnisse haben: Signal als Signal erkannt (true-positiv: tp), Signal als Untergrund erkannt (false-negativ: fn),
Untergrund als Signal erkannt (false-positiv: fp) und Untergrund als Untergrund erkannt (true-negativ: tn). Damit lassen sich Größen zur Bewertung eines
Lerners definieren. Die Reinheit $p$ gibt an wie Wahrscheinlich ein als Signal Klassifiziertes Datum auch Signal ist. Sie wird berechnet nach
\begin{equation}
	p=\frac{tp}{tp+fp}.
\end{equation}
Das Zweite Merkmal ist die Effizenz $r$. Sie gibt an wie viel Signal verloren wurde, also als Untergrund klassifiziert wurde. Sie wird berechnet nach
\begin{equation}
	r=\frac{tp}{tp+fn}
\end{equation}
Um diese Merkmale zu bestimmen, muss der Lerner Daten bekommen, mit denen er nicht trainiert wurde, für die aber trotzdem die richtige Klassifizierung bekannt
ist. Dazu teilt man die Trainingsdaten in $n$ Teile und Trainert dann mit $n-1$ Teilen. Die restlichen Daten werden dann zum Testen benutzt. Dieser Vorgang
sollte so Wiederholt werden, dass jeder Teil einmal als Testdaten genutzt wurde. Dadurch kann ein Mittelwert und Fehler für dei Merkmale bestimmt werden.
\subsection{Vorbereitung}
In dieser Auswertung werden Daten aus Monte-Carlo-Simulationen verwendet. Da einige der Features aus der Simulation bei echten Daten nicht bekannt sind, müssen
die gegeben Datensätze erst bereinigt werden. Dazu sollten alle Features, deren Label MC, Weigth oder Event beinhalten entfernt werden. Zusätzlich kann
ungültige Einträge wie NaN (Not a Number) oder inf (Infinity) vorkommen. Es gibt verschiedene Vorgehensweisen um mit solchen Einträgen zu arbeiten, hier wurde
der Mittelwert des Feature eingesetzt.
