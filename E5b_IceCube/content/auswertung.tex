\section{Auswertung}


\subsection{Die Feature-Selection}

Zur Auswahl der wichtigsten Features wird die im Abschnitt \ref{fs} beschriebene Methode verwendet. Der Parameter $k$ wird dabei für die drei untersuchten Klassifikatoren auf den Wert $k = 26$ gesetzt, da ab diesem Wert die im Folgenden betrachteten Güte-Werte der Klassifikatoren annähernd konstant sind und die benötigte Rechenzeit nur weiter zunimmt.


\subsection{Der Naive-Bayes-Klassifikator}

Als erster Lerner wird der Naive-Bayes-Klassifikator verwendet. Der Klassifikator gibt mithilfe der Methode \texttt{prodict\_proba} nach dem Fit durch die Trainings-Events eine Liste von Wahrscheinlichkeiten für die Test-Events aus, welche mit der richtigen und bekannten Klassifikation verglichen werden können. In Abbildung \ref{fig:NB_SD} ist die Verteilung der korrekt zugeordneten Events (aufgeteilt in Signal und Untergrund) in Abhängigkeit vom Scorecut aufgetragen. Der Scorecut bezeichnet die Wahrscheinlichkeit, oberhalb von der ein Event als Signal klassifiziert wird. Die Gesamtzahl der zu klassifizierenden Events ist 10000, die sich gleichmäßig auf Signal-Events und Background-Events aufteilen. Während die korrekte Klassifizierung von Background-Events für Scorecuts zwischen 0.1 und 0.9 einen annähernd konstanten Wert erreicht, steigt die Anzahl der korrekt identifizierten Signal-Events mit steigendem Scorecut.

\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{plots/bayes/Scoredistribution}
	\caption{Plot der Scoreverteilung des Naive-Bayes-Klassifikators.}
	\label{fig:NB_SD}
\end{figure}

Werden Präzision und Reinheit in Abhängigkeit vom Scorecut geplottet, ergeben sich die in Abbildung \ref{fig:NB_PRT} dargestellten Zusammenhänge: Während die Präzision einen annähernd konstanten Wert von 90\% über den Scorecut-Bereich zwischen 0.1 und 0.9 erreicht, liegt die Effizienz z.T. deutlich darunter und sinkt mit größer gewähltem Scorecut bis hin zu Werten von ca. 40\%. Je nach benötigter Effizienz des Lerners ist also ein niedrig gewählter Scorecut ratsam.

\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{plots/bayes/precrecathresh}
	\caption{Plot der Abhängigkeit von Präzision und Effizienz in Abhängigkeit vom Scorecut beim Naive-Bayes-Klassifikator. Der Plot wurde mit dem Paket \texttt{yellowbrick} \cite{yellowbrick} erstellt. Die eingefärbten Flächen entsprechen der Ungenauigkeit der Präzision bzw. Effizienz, welche mithilfe einer Kreuzvalidierung erzeugt wurden.}
	\label{fig:NB_PRT}
\end{figure}

In Abbildung \ref{fig:NB_ROC} ist die \enquote{Receiver-Operating-Characteristic}-Kurve (kurz: ROC) für den Naive-Bayes-Klassifikator abgebildet. Zur Erstellung der Kurve werden für verschiedene Scorecuts die True-Positive-Rate (die Wahrscheinlichkeit für die korrekte Klassifikation eines Signals) und die False-Positive-Rate (die Wahrscheinlichkeit für eine falsche Klassifikation zu einem Signal) aufeinander aufgetragen. Die Fläche unter der Kurve (\textit{engl.} area under curve, kurz: AUC) beträgt 0.91 und kann als Güte des Lerners interpretiert werden. Im schlechtesten Fall beträgt sie 0.5, was einer zufälligen Klassifikation gleichkommt (angedeutet durch die gestrichelte Linie in Abbildung \ref{fig:NB_ROC}). Im besten Fall wäre die AUC 1.0: Diese Fläche entspräche einer perfekten Klassifikation. 


\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{plots/bayes/ROC}
	\caption{Plot der ROC-Kurve des Naive-Bayes-Klassifikators.}
	\label{fig:NB_ROC}
\end{figure}


\subsection{Der k-Nearest-Neighbors-Klassifikator}

Analog zum Naive-Bayes-Klassifikator ergeben sich für den k-Nearest-Neighbors-Klas\-si\-fi\-ka\-tor die in den Abbildungen \ref{fig:NN_SD}, \ref{fig:NN_PRT} und \ref{fig:NN_ROC} dargestellten Plots. Zur Berechnung von \texttt{predict\_proba} werden $k = 15$ nächste Nachbarn verwendet, da sich hiermit in diesem Fall die höchste Präzision erreichen lässt. Abbildung \ref{fig:NN_SD} zeigt die Scoreverteilung für den k-Nearest-Neighbors-Klassifikator. Es liegen 15 Bins vor, da $k = 15$ gewählt wurde und somit die Wahrscheinlichkeit für die Klassifikation nur 15 verschiedene Werte annehmen kann. Auffällig im Vergleich zum Naive-Bayes-Klassifikator ist, dass die Verteilung deutlich symmetrischer ist. Diese Symmetrie findet sich auch wieder, wenn Präzision und Effizienz auf den Scorecut abgebildet werden (s. Abb. \ref{fig:NN_PRT}): Der Schnittpunkt der Graphen liegt deutlich näher an 50\% als beim vorangegangenen Klassifikator. Auffällig ist auch, dass eine hohe Präzision direkt mit einer deutlich geringeren Effizienz einhergeht als beim Naive-Bayes-Klassifikator, da die Effizienz mit steigendem Scorecut schnell fällt. Die ROC-Kurve ist dagegen ein wenig weiter in der linken oberen Ecke zentriert (s. Abb. \ref{fig:NN_ROC}), was sich auch in einem höheren Flächeninhalt unter der Kurve von AUC = 0.93 wiederspiegelt.

\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{plots/neigh/Scoredistribution}
	\caption{Plot der Scoreverteilung des Nearest-Neighbors-Klassifikators.}
	\label{fig:NN_SD}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{plots/neigh/precrecathresh}
	\caption{Plot der Abhängigkeit von Präzision und Effizienz in Abhängigkeit vom Scorecut beim Nearest-Neighbors-Klassifikator. Der Plot wurde mit dem Paket \texttt{yellowbrick} \cite{yellowbrick} erstellt. Die eingefärbten Flächen entsprechen der Ungenauigkeit der Präzision bzw. Effizienz, welche mithilfe einer Kreuzvalidierung erzeugt wurden.}
	\label{fig:NN_PRT}
\end{figure}


\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{plots/neigh/ROC}
	\caption{Plot der ROC-Kurve des Nearest-Neighbors-Klassifikators.}
	\label{fig:NN_ROC}
\end{figure}



\subsection{Der Random-Forest-Klassifikator}

Der Random-Forest, der für diese Datenauswertung verwendet wurde, besteht aus 15 Bäumen, da sich hiermit ein guter Ausgleich zwischen verwendeter Rechenzeit und guter Leistung des Klassifikators erreicht werden konnte. Die Scoreverteilung in Abbildung \ref{fig:RF_SD} zeigt eine sehr eindeutige Trennung von Signal und Hintergrund für Scorecuts in Bereich um 45\%. Diese Eigenschaft kann auch der Abbildung \ref{fig:RF_PRT} entnommen werden, in der Präzision und Effizienz auf den Scorecut aufgetragen worden sind: Sowohl Präzision als auch Effizienz können durch die Wahl eines Scorecuts von ca. 45\% so gewählt werden, dass beide Werte bei ca. 95\% liegen. Mit einem Scorecut von 80\% ließe sich hingegen ein noch höhere Präzision von 99\% erreichen. Die Effizienz läge dabei immer noch bei einem (im Vergleich zu den anderen Lernern) sehr guten Wert von knapp 85\%. Entsprechend gut fällt auch die Bewertung durch die ROC-Kurve (s. Abb. \ref{fig:RF_ROC}) aus: Die AUC beträgt hier 0.98.

Im Gegensatz zu den anderen beiden Lernern kann beim Random-Forest zudem noch bewertet werden, welche Features am wichtigsten für die Klassifikation sind. Die Ergebnisse sind der Abbildung \ref{fig:RF_FI} zu entnehmen. Die Zahlen an den Balken entsprechen der Spaltennummer der entsprechenden Features nach der Feature-Selection. Die fünf am höchsten vom Random-Forest bewerteten Features sind in absteigender Reihenfolge \texttt{LineFit\_TT.zenith}, \texttt{LineFit\_TTParams.lf\_vel\_z}, \texttt{SPEFit2\_TT.zenith}, \texttt{Line\-Fit\_TT\-Params.lf\_vel} und \texttt{SplineMPEDirecHitsC.n\_dir\_doms}. 

\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{plots/forest/Scoredistribution}
	\caption{Plot der Scoreverteilung des Random-Forest-Klassifikators.}
	\label{fig:RF_SD}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{plots/forest/precrecathresh}
	\caption{Plot der Abhängigkeit von Präzision und Effizienz in Abhängigkeit vom Scorecut beim Random-Forest-Klassifikator. Der Plot wurde mit dem Paket \texttt{yellowbrick} \cite{yellowbrick} erstellt. Die eingefärbten Flächen entsprechen der Ungenauigkeit der Präzision bzw. Effizienz, welche mithilfe einer Kreuzvalidierung erzeugt wurden.}
	\label{fig:RF_PRT}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{plots/forest/ROC}
	\caption{Plot der ROC-Kurve des Random-Forest-Klassifikators.}
	\label{fig:RF_ROC}
\end{figure}


\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{plots/forest/featureImportance}
	\caption{Die zwanzig wichtigsten Features beim Random-Forest-Klassifikator.}
	\label{fig:RF_FI}
\end{figure}


\subsection{Vergleich der Laufzeit der Klassifikatoren}

Die Spezifikation des verwendeten Prozessors zur Eventklassifikation lautet \texttt{Intel® Core™ i5-6200U CPU @ 2.30GHz × 4}. Die folgenden Zeitangaben beziehen sind jeweils auf einen der verwendeten Lerner und die zum Trainieren und Testen nötige Zeit. Um statistisch signifikante Werte zu erhalten wurde jeweils über 5 Durchgänge gemittelt. Der Naive-Bayes-Klassifikator benötigt $(23.1 \pm 0.2) \,\text{s}$. Fast zehn Sekunden schneller ist der k-Nearest-Neighbors-Klassifikator mit $(14.1 \pm 0.2) \,\text{s}$. Noch etwas weniger Zeit benötigt der Random-Forest-Klassifikator: Er braucht $(13.8 \pm 0.2) \,\text{s}$, bis die \texttt{predict\_proba} Methode ausgeführt wurde.\textsl{}

\subsection{Beispielhafte Forderung einer Präzision von mehr als 90\%}

Werden 90\% Präzision von der Klassifikation als Signal gefordert, muss der Scorecut bei den verschiedenen Lernern entsprechend gesetzt werden. Wie der Abbildung \ref{fig:NB_PRT} zu entnehmen ist, bilden 90\% Präzision beim Naive-Bayes-Klassifikator gerade ein Plateau. Um die genannte Forderung zu erreichen, müsste ein Scorecut oberhalb von 44.5\% gesetzt werden. Die Effizienz wäre damit zwangsläufig kleiner als 62\%. Eine etwas höhere Effizienz lässt sich bei einer Präzision von 90\% beim k-Nearest-Neighbors-Klassifikator erreichen: Der Scorecut muss oberhalb von 69\% gesetzt werden (s. Abb. \ref{fig:NN_PRT}). Die Effizienz liegt dadurch bei einem Wert von 75\% -- eine Verbesserung im Vergleich zum Naive-Bayes-Klassifikator. Wird die Forderung an den Random-Forest (s. Abb. \ref{fig:RF_PRT}) gestellt, ergibt sich ein Scorecut oberhalb von 27\%. Die Effizienz beträgt hier 96\%. Erst bei deutlich höheren geforderten Präzisionen sinkt diese auf ähnlich geringe Werte wie bei den anderen beiden Lernern: Wird der Scorecut auf 75\% gesetzt, lässt sich eine Präzision von 99\% erreichen, während die Effizienz nach wie vor bei 86\% liegt, was immer noch deutlich über der der anderen Lerner bei geringeren Präzisionen liegt.